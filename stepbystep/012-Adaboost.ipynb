{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X = X[y<2, :2]\n",
    "y = y[y<2]\n",
    "\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], color='red')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], color='blue')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意 AdaBoost 标签数据 是+1 和-1， 而非1和0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1, -1,  1, -1,  1, -1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1,  1, -1,  1,\n",
       "       -1, -1, -1,  1,  1, -1,  1, -1, -1,  1, -1, -1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1, -1, -1, -1,  1, -1,  1,  1, -1, -1,  1,  1,  1, -1,\n",
       "       -1, -1,  1,  1, -1, -1, -1])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test==0] = -1\n",
    "y_train[y_train==0] = -1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    dataMat = np.matrix([\n",
    "        [1. , 2.1],\n",
    "        [2. , 1.1],\n",
    "        [1.3, 1.],\n",
    "        [1. , 1. ],\n",
    "        [2. , 1.]\n",
    "    ])\n",
    "    \n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    \n",
    "    return dataMat, classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat, classLabels = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, -1.0, -1.0, 1.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0] , 1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "    return retArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf #init error sum, to +infinity\n",
    "    for i in range(n):#loop over all dimensions\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1):#loop over all range in current dimension\n",
    "            for inequal in ['lt', 'gt']: #go over less than and greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#call stump classify with i, j, lessThan\n",
    "                errArr = mat(ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr  #calc total error multiplied by D\n",
    "#                 print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mat(ones((5,1))/ 5)\n",
    "result = buildStump(dataMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)   #init D to all equal\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#build Stump\n",
    "        print(\"D:\",D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n",
    "        bestStump['alpha'] = alpha  \n",
    "        weakClassArr.append(bestStump)                  #store Stump Params in Array\n",
    "        #print \"classEst: \",classEst.T\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #exponent for D calc, getting messy\n",
    "        D = multiply(D,exp(expon))                              #Calc New D for next iteration\n",
    "        D = D/D.sum()\n",
    "        #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "        aggClassEst += alpha*classEst\n",
    "        print(\"aggClassEst: \",aggClassEst.T)\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print (\"total error: \",errorRate)\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr,aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0\n"
     ]
    }
   ],
   "source": [
    "classifierArr, aggClassEst = adaBoostTrainDS(dataMat, classLabels, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = mat(datToClass)#do stuff similar to last aggClassEst in adaBoostTrainDS\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'], classifierArr[i]['thresh'],classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        print(aggClassEst)\n",
    "    return sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = adaClassify([0,0], classifierArr)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n",
      "[[ 2.56198199]\n",
      " [-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = adaClassify([[5,5] , [0,0]], classifierArr)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现AdaBoost分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostClassifier():\n",
    "    def __init__(self, numIt=40):\n",
    "        self.classifierArr_ = None\n",
    "        self.numIt_ = numIt \n",
    " \n",
    "    def stumpClassify(self, dataMatrix, dimen, threshVal, threshIneq):\n",
    "        retArray = np.ones((np.shape(dataMatrix)[0] , 1))\n",
    "        if threshIneq == 'lt':\n",
    "            retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "        else:\n",
    "            retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "        return retArray\n",
    "    \n",
    "    def buildStump(self, dataArr,classLabels,D):\n",
    "        dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "        m,n = shape(dataMatrix)\n",
    "        numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "        minError = inf #init error sum, to +infinity\n",
    "        for i in range(n):#loop over all dimensions\n",
    "            rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "            stepSize = (rangeMax-rangeMin)/numSteps\n",
    "            for j in range(-1,int(numSteps)+1):#loop over all range in current dimension\n",
    "                for inequal in ['lt', 'gt']: #go over less than and greater than\n",
    "                    threshVal = (rangeMin + float(j) * stepSize)\n",
    "                    predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#call stump classify with i, j, lessThan\n",
    "                    errArr = mat(ones((m,1)))\n",
    "                    errArr[predictedVals == labelMat] = 0\n",
    "                    weightedError = D.T*errArr  #calc total error multiplied by D\n",
    "    #                 print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                    if weightedError < minError:\n",
    "                        minError = weightedError\n",
    "                        bestClasEst = predictedVals.copy()\n",
    "                        bestStump['dim'] = i\n",
    "                        bestStump['thresh'] = threshVal\n",
    "                        bestStump['ineq'] = inequal\n",
    "        return bestStump,minError,bestClasEst\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        weakClassArr = []\n",
    "        m = shape(X)[0]\n",
    "        D = mat(ones((m,1))/m)   #init D to all equal\n",
    "        aggClassEst = mat(zeros((m,1)))\n",
    "        for i in range(self.numIt_):\n",
    "            bestStump,error,classEst = buildStump(X,y,D)#build Stump\n",
    "#             print(\"D:\",D.T)\n",
    "            alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n",
    "            bestStump['alpha'] = alpha  \n",
    "            weakClassArr.append(bestStump)                  #store Stump Params in Array\n",
    "            #print \"classEst: \",classEst.T\n",
    "            expon = multiply(-1*alpha*mat(y).T,classEst) #exponent for D calc, getting messy\n",
    "            D = multiply(D,exp(expon))                              #Calc New D for next iteration\n",
    "            D = D/D.sum()\n",
    "            #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "            aggClassEst += alpha*classEst\n",
    "#             print(\"aggClassEst: \",aggClassEst.T)\n",
    "            aggErrors = multiply(sign(aggClassEst) != mat(y).T,ones((m,1)))\n",
    "            errorRate = aggErrors.sum()/m\n",
    "#             print (\"total error: \",errorRate)\n",
    "            if errorRate == 0.0: break\n",
    "        self.classifierArr_ = weakClassArr\n",
    "        return self \n",
    " \n",
    "    def predict(self, X_test):\n",
    "        assert self.classifierArr_ is not None, \\\n",
    "                \"must fit before predi ct!\"\n",
    "        dataMatrix = mat(X_test)#do stuff similar to last aggClassEst in adaBoostTrainDS\n",
    "        m = shape(dataMatrix)[0]\n",
    "        aggClassEst = mat(zeros((m,1)))\n",
    "        for i in range(len(self.classifierArr_)):\n",
    "            classEst = stumpClassify(dataMatrix,\n",
    "                                     self.classifierArr_[i]['dim'], \n",
    "                                     self.classifierArr_[i]['thresh'],\n",
    "                                     self.classifierArr_[i]['ineq'])\n",
    "            aggClassEst += self.classifierArr_[i]['alpha']*classEst\n",
    "#             print(aggClassEst)\n",
    "        return sign(aggClassEst).getA().flatten()\n",
    "    \n",
    "    def score(self, X_predict, y_test):\n",
    "        y_predict = self.predict(X_predict)\n",
    "        return accuracy_score(y_predict,y_test)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"AdaBoostClassifier( )  {} \".format(self.classifierArr_)\n",
    "\n",
    "ada_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试单独数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier( )  [{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453}, {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565}, {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}] "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat, classLabels = loadSimpData()\n",
    "ada_clf.fit(dataMat, classLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf.predict([[5,5] , [0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试鸢尾花数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf.fit(X_train, y_train)\n",
    "pred = ada_clf.predict(X_test)\n",
    "ada_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1.\n",
      " -1.  1. -1.  1. -1.  1. -1.]\n",
      "[-1  1 -1 -1  1  1  1  1  1  1  1  1  1 -1 -1 -1  1 -1 -1  1  1  1  1  1\n",
      " -1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):      #general function to parse tab -delimited floats\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) #get number of fields \n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr =[]\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat,labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = loadDataSet('./data/horseColicTraining2.txt')\n",
    "X_test , y_test = loadDataSet('./data/horseColicTest2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7761194029850746"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(numIt=200)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "ada_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8809523809523809"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314606741573034"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872340425531915"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 10],\n",
       "       [ 5, 37]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
